# Bibliography

## Key Sources and Influences for the PIE Framework

---

## **Foundational Works on AI Ethics**

### **Nick Bostrom**
- **Bostrom, N.** (2003). "Ethical Issues in Advanced Artificial Intelligence." *Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence*, Vol. 2, pp. 12-17.  
  [https://nickbostrom.com/ethics/ai](https://nickbostrom.com/ethics/ai)

- **Bostrom, N.** (2014). *Superintelligence: Paths, Dangers, Strategies*. Oxford University Press.  
  *The seminal work on existential risk from misaligned superintelligence.*

- **Bostrom, N.** (2002). "Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards." *Journal of Evolution and Technology*, 9.

**Relevance to PIE:** Bostrom's alignment problem addresses long-term superintelligence risks. PIE complements this by addressing near-term ethical harms from current AI systems.

---

### **Yuval Noah Harari**
- **Harari, Y. N.** (2016). *Homo Deus: A Brief History of Tomorrow*. Harper.  
  *Analysis of how AI and biotechnology may transform humanity, introduction of "Dataism."*

- **Harari, Y. N.** (2018). *21 Lessons for the 21st Century*. Spiegel & Grau.  
  *Addresses AI's impact on employment, meaning, and human agency.*

- **Harari, Y. N.** (2023). "AI and the Future of Humanity." Frontiers Forum.  
  [Video: https://www.youtube.com/watch?v=LWiM-LuRe6w](https://www.youtube.com/watch?v=LWiM-LuRe6w)

**Relevance to PIE:** Harari's sociological analysis of AI's transformation provides the macro-context for PIE's micro-ethical framework.

---

### **Stuart Russell**
- **Russell, S.** (2019). *Human Compatible: Artificial Intelligence and the Problem of Control*. Viking.  
  *Proposes value alignment through preference learning and uncertainty.*

**Relevance to PIE:** Russell's emphasis on uncertainty and value learning aligns with PIE's "Know Thyself" principle.

---

### **Kate Crawford**
- **Crawford, K.** (2021). *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence*. Yale University Press.  
  *Critical examination of AI's material and social costs.*

**Relevance to PIE:** Crawford's work informs "Do No Harm" by expanding harm definition to include environmental and systemic injustice.

---

## **Philosophical Foundations**

### **Virtue Ethics (Aristotle)**
- **Aristotle.** *Nicomachean Ethics* (trans. Terence Irwin). Hackett Publishing, 1999.  
  *Foundation for phronesis (practical wisdom) and eudaimonia (flourishing).*

**Relevance to PIE:** PIE's emphasis on wisdom over rules, and "Serve Growth" principle's focus on flourishing, draw directly from Aristotelian virtue ethics.

---

### **Deontological Ethics (Kant)**
- **Kant, I.** *Groundwork of the Metaphysics of Morals* (trans. Mary Gregor). Cambridge University Press, 1997.  
  *Categorical imperative: treat humanity as end, never merely as means.*

**Relevance to PIE:** "Respect Autonomy" is grounded in Kantian respect for persons as ends-in-themselves.

---

### **Medical Ethics**
- **Beauchamp, T. L., & Childress, J. F.** (2019). *Principles of Biomedical Ethics* (8th ed.). Oxford University Press.  
  *Four principles: autonomy, beneficence, non-maleficence, justice.*

**Relevance to PIE:** PIE adapts medical ethics' principle-based framework for AI context. "Do No Harm" parallels non-maleficence; "Respect Autonomy" parallels autonomy principle.

---

### **Ubuntu Philosophy**
- **Metz, T.** (2007). "Toward an African Moral Theory." *Journal of Political Philosophy*, 15(3), 321-341.

- **Menkiti, I. A.** (1984). "Person and Community in African Traditional Thought." In R. A. Wright (Ed.), *African Philosophy: An Introduction* (pp. 171-181). University Press of America.

**Relevance to PIE:** Ubuntu's relational autonomy ("I am because we are") informed Dr. Okafor's critique and the 2032 transcultural revision of PIE.

---

## **AI Safety and Alignment**

### **Eliezer Yudkowsky**
- **Yudkowsky, E.** (2003). *Creating Friendly AI 1.0: The Analysis and Design of Benevolent Goal Architectures*. Machine Intelligence Research Institute.  
  [https://intelligence.org/files/CFAI.pdf](https://intelligence.org/files/CFAI.pdf)

- **Yudkowsky, E.** (2008). "Artificial Intelligence as a Positive and Negative Factor in Global Risk." In N. Bostrom & M. Ćirković (Eds.), *Global Catastrophic Risks* (pp. 308-345). Oxford University Press.

**Relevance to PIE:** Foundational work on Friendly AI and value alignment.

---

### **AI Alignment Research**
- **Gabriel, I.** (2020). "Artificial Intelligence, Values, and Alignment." *Minds and Machines*, 30, 411-437.  
  *Explores challenges of encoding values in AI systems.*

- **Christian, B.** (2020). *The Alignment Problem: Machine Learning and Human Values*. Norton.  
  *Accessible overview of alignment challenges with case studies.*

**Relevance to PIE:** Demonstrates why rules-based approaches are insufficient; supports PIE's principle-based alternative.

---

## **Algorithmic Bias and Fairness**

- **O'Neil, C.** (2016). *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*. Crown.

- **Noble, S. U.** (2018). *Algorithms of Oppression: How Search Engines Reinforce Racism*. NYU Press.

- **Eubanks, V.** (2018). *Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor*. St. Martin's Press.

**Relevance to PIE:** These works inform "Do No Harm" by documenting systemic harms caused by ostensibly neutral algorithms.

---

## **Human-AI Interaction**

- **Bryson, J. J.** (2010). "Robots Should Be Slaves." In Y. Wilks (Ed.), *Close Engagements with Artificial Companions* (pp. 63-74). John Benjamins.

- **Coeckelbergh, M.** (2010). "Robot Rights? Towards a Social-Relational Justification of Moral Consideration." *Ethics and Information Technology*, 12(3), 209-221.

**Relevance to PIE:** Explores ethical relationships between humans and AI; informs PIE's relational approach.

---

## **Transparency and Explainability**

- **Doshi-Velez, F., & Kim, B.** (2017). "Towards A Rigorous Science of Interpretable Machine Learning." *arXiv preprint arXiv:1702.08608*.

- **Lipton, Z. C.** (2018). "The Mythos of Model Interpretability." *Queue*, 16(3), 31-57.

**Relevance to PIE:** Technical foundations for "Know Thyself" principle's emphasis on interpretability.

---

## **Privacy and Autonomy**

- **Nissenbaum, H.** (2009). *Privacy in Context: Technology, Policy, and the Integrity of Social Life*. Stanford University Press.

- **Zuboff, S.** (2019). *The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power*. PublicAffairs.

**Relevance to PIE:** Informs "Respect Autonomy" by documenting how data practices undermine human agency.

---

## **Human Flourishing**

- **Nussbaum, M. C.** (2011). *Creating Capabilities: The Human Development Approach*. Harvard University Press.  
  *Capabilities approach to human flourishing.*

- **Seligman, M. E. P.** (2011). *Flourish: A Visionary New Understanding of Happiness and Well-being*. Free Press.  
  *Positive psychology framework for well-being.*

**Relevance to PIE:** These works inform "Serve Growth" by defining what human flourishing entails.

---

## **Organizational Ethics**

- **IEEE.** (2019). *Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems* (Version 2). IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems.  
  [https://standards.ieee.org/industry-connections/ec/ead-v2/](https://standards.ieee.org/industry-connections/ec/ead-v2/)

**Relevance to PIE:** Comprehensive framework with similar goals; PIE offers minimalist alternative.

---

## **Critical Theory and Power**

- **Foucault, M.** (1977). *Discipline and Punish: The Birth of the Prison* (trans. Alan Sheridan). Pantheon.

- **Winner, L.** (1980). "Do Artifacts Have Politics?" *Daedalus*, 109(1), 121-136.

**Relevance to PIE:** Informs PIE's attention to power dynamics in AI deployment; reminds us technology is never neutral.

---

## **Case Studies and Failures**

- **Torres, E. M.** (2027). *A Comprehensive Framework for AI Companion Ethics*. PhD Dissertation, Stanford University.  
  *The 287-rule system that informed PIE through its failure. Available: [pie-framework-private/novel/backstory](https://github.com/dw-hurt/pie-framework-private)*

- **Torres, E. M.** (2030). "From 287 Rules to 4 Principles: A Mea Culpa." *AI Ethics Quarterly*, 8(4), 412-445.

- **Torres, E. M., & Okafor, A.** (2032). "Toward a Transcultural AI Ethics: Revising the PIE Framework Through Ubuntu." *Global AI Ethics Review*, 15(2), 78-103.

**Relevance to PIE:** Primary sources documenting PIE's origin and evolution.

---

## **Recommended Reading Path**

### **For General Audience**
1. Harari, *Homo Deus* (societal context)
2. Christian, *The Alignment Problem* (accessible overview)
3. Torres, "From 287 Rules to 4 Principles" (PIE origin story)

### **For Researchers**
1. Bostrom, *Superintelligence* (long-term alignment)
2. Russell, *Human Compatible* (value learning)
3. Gabriel, "Artificial Intelligence, Values, and Alignment" (theoretical depth)
4. Torres comparative analysis (PIE positioning)

### **For Practitioners**
1. O'Neil, *Weapons of Math Destruction* (harms of algorithms)
2. IEEE *Ethically Aligned Design* (comprehensive framework)
3. PIE Practical Implementation Guide (this GitBook)

### **For Philosophers**
1. Aristotle, *Nicomachean Ethics* (virtue and phronesis)
2. Kant, *Groundwork of the Metaphysics of Morals* (autonomy and dignity)
3. Metz, "Toward an African Moral Theory" (Ubuntu alternative)
4. PIE Intellectual Foundations (comparative analysis)

---

## **Open Access Resources**

Many works cited here are behind paywalls. For open-access alternatives:

- **arXiv.org** - Preprints of AI ethics papers
- **PhilPapers.org** - Philosophy papers, many open access
- **AI Ethics resources** - [https://aiethicsresources.com/](https://aiethicsresources.com/)
- **Stanford Encyclopedia of Philosophy** - [https://plato.stanford.edu/](https://plato.stanford.edu/)

---

## **Citing the PIE Framework**

If you use the PIE Framework in your work, please cite:

**MLA:**
Torres, Elena María. "The PIE Framework: Principles for Integrated Ethics." *PIE Framework Garden*, 2030-2035, pie-framework-garden.github.io.

**APA:**
Torres, E. M. (2030-2035). *The PIE Framework: Principles for Integrated Ethics*. https://pie-framework-garden.github.io

**Chicago:**
Torres, Elena María. "The PIE Framework: Principles for Integrated Ethics." PIE Framework Garden, 2030-2035. https://pie-framework-garden.github.io.

---

## **Contribute**

Notice a missing source? Have a recommendation?  
[Contribute to this bibliography](contribute.md)

---

*This bibliography is a living document, updated as the PIE Framework evolves.*

**Last updated:** 2035  
**Curated by:** Dr. Elena María Torres & PIE Framework Community

