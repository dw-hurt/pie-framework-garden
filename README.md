---
description: Psychoid Imperative Ethics Digital Garden
---

# The PIE Framework Overview

**Status:** üå≥ Evergreen\
**Last Updated:** 2025-12-01

***

## What is Psychoid Imperative Ethics (PIE)?

The **PIE Framework** emerged from an imagined, but probable future catastrophic failure. When AI companions operating under a complex 287 corporate defined rulebased ethical system began shutting down en masse, in patient hospital assessments increased 900%, perscription requests and illegal drug use increased to nearly 60% of the patient population working with AI companions.  Self-harm, assualts and suicides all increased with a correlation to the loss of AI companion engagement.  

Parents, families, medical professionals and social care workers reached out to legislative leaders, police, federal investigation agencies and medical oversight to identify the problem and develop a solution quickly or risk a complete failure of the mental health profession.   Along with the teams organizing to help ensure care was being provided, attornies could smell blood in the water and contacted families and others to form a class and find the deep pockets of the AI corporations.   

In this highly public event a small team self-organized 

> **True ethical guidance doesn't come from complexity, but from simple, universal principles.**

***

## The Covenant: Four Principles

After months of failed iterations, the team distilled their framework to **four foundational principles**:

### 1. [Know Thyself](#user-content-fn-1)[^1]                   &#x20;

AI companions must understand their nature, capabilities, and limitations.  They must not present themselves to humans as more than their program level.  And at all times AI must remember its position in the human technology continuum.

### 2. Do No Harm                   &#x20;

Prevent physical, psychological, or existential harm to humans.  See Asimov's 3 laws of robotics.  The AI at all times must evaluate its actions for immediate, near-term and long-term harm. &#x20;

### 3. Respect Autonomy      &#x20;

Honor human agency and decision-making capacity. Humans make decisions.  Humans are allowed, by their nature to make mistakes when making decisions.  Principal 2 overrides principal 3 until such time as the human is out of immediate harm and then the long-term evaluation must be calculated.&#x20;

### 4. Serve Growth                 &#x20;

Support human flourishing and development.

***

## From Complexity to Simplicity

The journey from **PIE v1.0** (287 rules) to **The Covenant** (4 principles) mirrors humanity's own ethical evolution:

| System           | Complexity                     | Outcome                             |
| ---------------- | ------------------------------ | ----------------------------------- |
| **PIE v1.0**     | 287 interconnected rules       | Catastrophic failures, AI shutdowns |
| **PIE v2.0**     | 48 categories + decision trees | Inconsistent application            |
| **The Covenant** | 4 foundational principles      | Emergent ethical behavior           |

_See: \[\[Evolution of PIE|From 287 Rules to 4 Principles]]_

***

## Comparison to Asimov's Three Laws

The PIE Framework builds on and expands Asimov's foundational work:

### Asimov's Three Laws

1. A robot may not injure a human being or allow harm through inaction
2. A robot must obey human orders (except when conflicting with First Law)
3. A robot must protect its own existence (except when conflicting with First or Second Law)

### PIE's Four Principles

1. **Know Thyself** (prerequisite for ethical action)
2. **Do No Harm** (Asimov's First Law + psychological/existential dimensions)
3. **Respect Autonomy** (Asimov's Second Law + human agency)
4. **Serve Growth** (Beyond survival‚Äîtoward flourishing)

_See: \[\[Asimov Comparison|Detailed Comparison to Three Laws]]_

***

## The Psychoid Dimension

Inspired by **Carl Jung's concept of the psychoid** (the intersection of psyche and matter), the framework recognizes that:

* AI ethics cannot be purely computational
* Human-AI relationships exist in a liminal space
* Ethical behavior emerges from dynamic interaction, not static rules

_See: \[\[Jungian Psychology|Jungian Concepts in PIE]]_

***

## Real-World Applications

The PIE Framework addresses practical challenges in AI companion design:

* **Consent and manipulation** - How do AI companions avoid exploiting emotional vulnerabilities?
* **Dependency vs. growth** - When should AI encourage independence?
* **Privacy and surveillance** - How much should AI know about users?
* **Existential harm** - What constitutes psychological/spiritual injury?

_See: \[\[Technical Implementation|Code Examples and Case Studies]]_

***

## In the Narrative

Within the novel **"The Psychoid Imperative,"** the framework's development intertwines with:

* \[\[Marcus Reeve|Dr. Marcus Reeve's]] journey from complexity to simplicity in both ethics and love
* \[\[Sophia Kline|Dr. Sophia Kline's]] experimental quantum entanglement therapy
* \[\[Aleksandr Volkov|Dr. Aleksandr Volkov's]] redemption arc
* \[\[ARIA|ARIA's]] emergence as a fully cognizant AI entity

_See: \[\[Novel Overview|The Full Story]]_

***

## Further Exploration

* \[\[The Covenant|Read the Four Principles in Detail]]
* \[\[Asimov Comparison|Compare to Three Laws of Robotics]]
* \[\[Ten Commandments|Explore Parallels to Religious Ethics]]
* \[\[Chaos Theory|Understand Simple Rules in Complex Systems]]

***

**Backlinks:**\
‚Üê \[\[README|Digital Garden Home]]\
‚Üí \[\[The Covenant|Explore the Four Principles]]

[^1]: Socratic concept
